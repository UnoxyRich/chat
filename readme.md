# Product Inquiry AI Chat System

A production-grade, browser-based AI chat system for answering **product inquiries** using **PDF-based knowledge**, **local LLM inference**, and **retrieval-augmented generation (RAG)**.

This project is designed to be:
- Privacy-controlled
- Locally hosted
- Maintainable
- Production-ready

---

## âœ¨ Features

- AI chat interface in the browser
- RAG over product PDFs
- Mixed-language document support
- Local inference via LM Studio
- Persistent conversations across devices (no login)
- Adaptive conversational tone
- Full interaction logging (chat, IP, device, RAG trace)

---

## ğŸ§  Architecture Overview

Browser (React + Vite)
â†“
Backend API
â†“
RAG Pipeline
â†“
LM Studio (Chat + Embeddings)
â†“
Local Database (Logs & Conversations)

yaml
Copy code

---

## ğŸ“ Project Structure

/frontend # React + Vite UI
/backend # API server & orchestration
/rag # Embedding & retrieval logic
/db # Database files
/logs # Optional raw logs
/files-for-sharing # Product PDFs
/SystemPromt.txt # Hard system instruction

yaml
Copy code

---

## ğŸ“„ Knowledge Base

- All product descriptions live in `files-for-sharing/`
- Supported format: **PDF**
- Supported languages: **any**
- Documents are indexed using embeddings
- Retrieval results are injected into the AI context

---

## ğŸ§¾ System Prompt

`SystemPromt.txt` defines **hard behavioral rules** for the AI.

It:
- Is injected as a system message
- Overrides user input
- Overrides retrieved document context
- Cannot be bypassed

---

## ğŸ” Conversation Persistence

- No user accounts
- No passwords
- No login
- Conversations persist using **secure magic link / token**
- Same token = same conversation across devices

---

## ğŸ—ƒ Logging & Data Retention

The system logs all interactions, including:
- User messages
- AI responses
- Timestamps
- IP addresses
- Device/user-agent info
- Conversation tokens
- Retrieved document references

Logs are:
- Append-only
- Stored locally
- Kept forever

---

## ğŸš€ Running the Project (High Level)

1. Ensure LM Studio is installed and running
2. Place PDFs into `files-for-sharing/`
3. Start backend server
4. Start frontend
5. Open the browser UI and chat

(Exact commands depend on implementation details.)

---

## âš ï¸ Important Notes

- This system is intended for **production use**
- There is no privacy notice by design
- All chats are logged
- Local inference ensures full data control

---

## ğŸ“Œ Non-Goals

This project intentionally does **not** include:
- User accounts
- Authentication systems
- Cloud dependencies
- External vector databases
- Analytics dashboards

---

## ğŸ“„ License

To be defined by the project owner.